{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, boxcox, yeojohnson\n",
    "from datetime import datetime\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.stats import zscore \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../Data/digital_marketing_campaign_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df_original):\n",
    "    \"\"\"\n",
    "    Processes the dataset by:\n",
    "    1. Dropping unnecessary columns\n",
    "    2. Encoding categorical features using one-hot encoding\n",
    "    3. Standardizing numerical features\n",
    "\n",
    "    Returns:\n",
    "    - df_scaled (numpy array): Standardized dataset\n",
    "    - df_encoded (DataFrame): Encoded dataset before scaling (for column reference)\n",
    "    - scaler (StandardScaler): Fitted scaler for inverse transformation\n",
    "    \"\"\"\n",
    "    # Drop unwanted columns\n",
    "    df_drop = df_original.drop(columns=['AdvertisingPlatform', 'AdvertisingTool', 'CustomerID'])\n",
    "\n",
    "    # Encode categorical variables\n",
    "    columns_to_encode = ['Gender', 'CampaignChannel', 'CampaignType']\n",
    "    df_encoded = pd.get_dummies(df_drop, columns=columns_to_encode, drop_first=False)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "    return df_scaled, df_encoded, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled, df_encoded, scaler = process_data(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_pca_kmeans(df_scaled, max_pca=10, k_min=2, k_max=15):\n",
    "    \"\"\"\n",
    "    Finds the optimal number of PCA components and K-Means clusters \n",
    "    using silhouette scores as the evaluation metric.\n",
    "\n",
    "    Parameters:\n",
    "    - df_scaled (numpy array): Standardized dataset\n",
    "    - max_pca (int): Maximum number of PCA components to consider (default: 10)\n",
    "    - k_min (int): Minimum number of clusters to test (default: 2)\n",
    "    - k_max (int): Maximum number of clusters to test (default: 15)\n",
    "\n",
    "    Returns:\n",
    "    - best_pca_n (int): Best number of PCA components\n",
    "    - best_k_for_best (int): Best number of clusters\n",
    "    - best_scores_for_best (list): Silhouette scores for different k-values\n",
    "    \"\"\"\n",
    "    # Define PCA and KMeans search ranges\n",
    "    pca_range = range(2, min(df_scaled.shape[1], max_pca) + 1)\n",
    "    k_range = range(k_min, k_max)\n",
    "    \n",
    "    overall_best_sil = -np.inf\n",
    "    best_pca_n = None\n",
    "    best_k_for_best = None\n",
    "    best_scores_for_best = None\n",
    "\n",
    "    # Loop over different numbers of PCA components\n",
    "    for n_components in pca_range:\n",
    "        pca = PCA(n_components=n_components, random_state=42)\n",
    "        X_pca_temp = pca.fit_transform(df_scaled)\n",
    "        \n",
    "        scores_temp = []\n",
    "        for k in k_range:\n",
    "            kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            labels_temp = kmeans_temp.fit_predict(X_pca_temp)\n",
    "            sil = silhouette_score(X_pca_temp, labels_temp)\n",
    "            scores_temp.append((k, sil))\n",
    "\n",
    "        best_for_this = max(scores_temp, key=lambda x: x[1])\n",
    "\n",
    "        if best_for_this[1] > overall_best_sil:\n",
    "            overall_best_sil = best_for_this[1]\n",
    "            best_pca_n = n_components\n",
    "            best_k_for_best = best_for_this[0]\n",
    "            best_scores_for_best = scores_temp\n",
    "\n",
    "    return best_pca_n, best_k_for_best, best_scores_for_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pca_n, best_k_for_best, best_scores_for_best = find_best_pca_kmeans(df_scaled, max_pca=10, k_min=2, k_max=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca_kmeans(df_scaled, best_pca_n, best_k_for_best):\n",
    "    \"\"\"\n",
    "    Applies PCA with the optimal number of components and performs K-Means clustering.\n",
    "\n",
    "    Parameters:\n",
    "    - df_scaled (numpy array): Standardized dataset\n",
    "    - best_pca_n (int): Best number of PCA components\n",
    "    - best_k_for_best (int): Best number of clusters\n",
    "\n",
    "    Returns:\n",
    "    - df_pca (numpy array): PCA-transformed dataset\n",
    "    - labels (numpy array): Cluster labels from K-Means\n",
    "    - kmeans (KMeans object): Fitted K-Means model\n",
    "    - pca_best (PCA object): Fitted PCA model\n",
    "    \"\"\"\n",
    "    pca_best = PCA(n_components=best_pca_n, random_state=42)\n",
    "    df_pca = pca_best.fit_transform(df_scaled)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=best_k_for_best, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(df_pca)\n",
    "\n",
    "    return df_pca, labels, kmeans, pca_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca, labels, kmeans, pca_best = apply_pca_kmeans(df_scaled, best_pca_n, best_k_for_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 3, ..., 3, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
